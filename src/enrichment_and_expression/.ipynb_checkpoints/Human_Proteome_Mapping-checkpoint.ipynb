{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path = '/Users/deagogishvili/Desktop/PublicationFiles/ALL_FILES_NEEDED'\n",
    "\n",
    "nsp_uniprot = my_path + '/uniprot_9606_formatted_lisa.tab'\n",
    "all_uniprot = my_path + '/uniprot_9606.tab'\n",
    "lhpsa = my_path + '/lhpsa_netsurfp_model_predictions.tsv'\n",
    "TM_uniprot = my_path + '/TM_proteins.tab'\n",
    "consensus = my_path + '/rna_consensus.tsv'\n",
    "lp_all = my_path + '/ready_to_use_data.csv'\n",
    "\n",
    "nsp_uniprot = pd.read_csv(nsp_uniprot, sep='\\t', engine='python') #NSP2 predictions for Uniprot\n",
    "lhpsa = pd.read_csv(lhpsa, sep='\\t', engine='python') # LHP predictions\n",
    "all_uniprot = pd.read_csv(all_uniprot, sep='\\t', engine='python') #all information from Uniprot only\n",
    "TM_uniprot = pd.read_csv(TM_uniprot, sep='\\t', engine='python') #annotated transmembrane proteins\n",
    "consensus = pd.read_csv(consensus, sep='\\t', engine='python') #mRNA expression consensus data from HPA\n",
    "lp_all = pd.read_csv(lp_all, sep=',', engine='python') #Structure-based definitions from Molpatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Annotated Transmembrane Proteins from Uniprot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TM_uniprot = list(TM_uniprot['Entry'])\n",
    "all_uniprot_without_tm = all_uniprot[~all_uniprot['Entry'].isin(TM_uniprot)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('all', len(nsp_uniprot.iloc[:,0]))\n",
    "\n",
    "# Remove disordered proteins\n",
    "nsp_uniprot = nsp_uniprot[nsp_uniprot['disorder'] < 0.5]\n",
    "print('< 0.5 Disorder', len(nsp_uniprot.iloc[:,0]))\n",
    "\n",
    "# Remove Large proteins\n",
    "#nsp_uniprot['length'] = nsp_uniprot['length'].astype(float)\n",
    "nsp_uniprot = nsp_uniprot[nsp_uniprot['length'] <= 800]\n",
    "print('Short Proteins', len(nsp_uniprot.iloc[:,0]))\n",
    "\n",
    "# remove ambiguous predictions\n",
    "nsp_uniprot = nsp_uniprot[nsp_uniprot['tasa_netsurfp2'] > 0]\n",
    "nsp_uniprot = nsp_uniprot[nsp_uniprot['thsa_netsurfp2'] > 0]\n",
    "nsp_uniprot = nsp_uniprot[nsp_uniprot['rhsa_netsurfp2'] > 0]\n",
    "nsp_uniprot = nsp_uniprot[nsp_uniprot['rhsa_netsurfp2'] < 1]\n",
    "print('TASA, THSA > 0 and 0 < RHSA < 1', len(nsp_uniprot.iloc[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_uniprot.columns = ['id', 'x1', 'x2', 'x3', 'Gene_ID', 'x4', 'x5', 'x6', 'length']\n",
    "all_uniprot = all_uniprot[['id', 'Gene_ID','length']]\n",
    "all_uniprot = all_uniprot.dropna(subset = ['Gene_ID'])\n",
    "\n",
    "hg = nsp_uniprot[['id', 'thsa_netsurfp2', 'rhsa_netsurfp2']] # hg = human genome\n",
    "hg = pd.merge(hg, all_uniprot, on='id')\n",
    "hg = pd.merge(hg, lhpsa, on='id')\n",
    "hg = hg.rename(columns = {'id': 'Uniprot_ID', 'thsa_netsurfp2': 'THSA', 'rhsa_netsurfp2':'RHSA', 'prediction':'LHPSA'}, inplace = False)\n",
    "hg = hg[['Uniprot_ID', 'Gene_ID', 'THSA', 'RHSA', 'LHPSA', 'length']]\n",
    "\n",
    "# discart multiple Gene_IDs, keep only the first one\n",
    "hg['Gene_ID'] = hg['Gene_ID'].astype(str)\n",
    "hg['Gene_ID'] = [x.split(';')[0] for x in hg['Gene_ID']]\n",
    "\n",
    "# Discard duplicate Gene_ID, keep the one with the highest THSA\n",
    "hg = hg.sort_values('THSA').drop_duplicates(subset=['Gene_ID'], keep='last') \n",
    "print(len(hg.iloc[:,0]))\n",
    "\n",
    "# Remove NaNs from Gene names\n",
    "hg = hg.dropna(subset = ['Gene_ID'])\n",
    "print(len(hg.iloc[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Curation without Transmembrane proteins in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_uniprot_without_tm.columns = ['id', 'x1', 'x2', 'x3', 'Gene_ID', 'x4', 'x5', 'x6', 'length']\n",
    "all_uniprot_without_tm = all_uniprot_without_tm[['id', 'Gene_ID', 'length']]\n",
    "\n",
    "# hg (human genome) without transmembrane proteins\n",
    "hg_without_tm = nsp_uniprot[['id', 'thsa_netsurfp2', 'rhsa_netsurfp2']]\n",
    "hg_without_tm = pd.merge(all_uniprot_without_tm, hg_without_tm, on='id')\n",
    "hg_without_tm = pd.merge(hg_without_tm, lhpsa, on='id')\n",
    "hg_without_tm = hg_without_tm.rename(columns = {'id': 'Uniprot_ID', 'thsa_netsurfp2': 'THSA', 'rhsa_netsurfp2':'RHSA', 'prediction':'LHPSA'}, inplace = False)\n",
    "hg_without_tm = hg_without_tm[['Uniprot_ID', 'Gene_ID', 'THSA', 'RHSA', 'LHPSA', 'length']]\n",
    "\n",
    "# discart multiple Gene_IDs, keep only the first one\n",
    "\n",
    "hg_without_tm['Gene_ID'] = hg_without_tm['Gene_ID'].astype(str)\n",
    "hg_without_tm['Gene_ID'] = [x.split(';')[0] for x in hg_without_tm['Gene_ID']]\n",
    "\n",
    "# Discard duplicate Gene_ID, keep the one with the highest THSA\n",
    "\n",
    "hg_without_tm = hg_without_tm.sort_values('THSA').drop_duplicates(subset=['Gene_ID'], keep='last') \n",
    "print(len(hg_without_tm.iloc[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Distribution Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('ticks')\n",
    "sns.set(font_scale = 1.55)\n",
    "fig, ax = plt.subplots(0,0)\n",
    "fig.set_size_inches(14, 5)\n",
    "\n",
    "sns.distplot(lp_all['thsa'], hist=False, kde=True, color='Blue', kde_kws={'shade': True, 'linewidth': 2})\n",
    "sns.distplot(hg['THSA'], hist=False, kde=True, color='crimson', kde_kws={'shade': True, 'linewidth': 2})\n",
    "sns.distplot(hg_without_tm['THSA'], hist=False, kde=True, color='goldenrod', kde_kws={'shade': True, 'linewidth': 2})\n",
    "#legend = ['Human proteome','Structure-based set']\n",
    "#plt.legend(legend, prop={'size': 15}, title = 'Data Set')\n",
    "#plt.title('',  size=30)\n",
    "plt.xlabel('THSA ($Å^2$)',  size=25)\n",
    "plt.ylabel('Density',  size=25)\n",
    "#fig.savefig(my_path + 'THSA.png', dpi = 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below is the code for RHSA, LHP and Protein length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(0,0)\n",
    "fig.set_size_inches(14, 5)\n",
    "sns.distplot(hg['RHSA'], hist=False, kde=True, color='crimson', kde_kws={'shade': True, 'linewidth': 2})\n",
    "sns.distplot(lp_all['rhsa'], hist=False, kde=True, color='Blue', kde_kws={'shade': True, 'linewidth': 2})\n",
    "sns.distplot(hg_without_tm['RHSA'], hist=False, kde=True, color='goldenrod', kde_kws={'shade': True, 'linewidth': 2})\n",
    "plt.xlabel('RHSA',  size=25)\n",
    "plt.ylabel('Density',  size=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(0,0)\n",
    "fig.set_size_inches(14, 5)\n",
    "sns.distplot(hg['LHPSA'], hist=False, kde=True, color='crimson', kde_kws={'shade': True, 'linewidth': 2})\n",
    "sns.distplot(lp_all['size'], hist=False, kde=True, color='Blue', kde_kws={'shade': True, 'linewidth': 2})\n",
    "sns.distplot(hg_without_tm['LHPSA'], hist=False, kde=True, color='goldenrod', kde_kws={'shade': True, 'linewidth': 2})\n",
    "plt.xlabel('LHP ($Å^2$)',  size=25)\n",
    "plt.ylabel('Density',  size=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(0,0)\n",
    "fig.set_size_inches(15, 5)\n",
    "sns.distplot(hg['length'], hist=False, kde=True, color='crimson', kde_kws={'shade': True, 'linewidth': 2})\n",
    "sns.distplot(lp_all['length'], hist=False, kde=True, color='Blue', kde_kws={'shade': True, 'linewidth': 2})\n",
    "sns.distplot(hg_without_tm['length'], hist=False, kde=True, color='goldenrod',kde_kws={'shade': True, 'linewidth': 2})\n",
    "\n",
    "plt.xlabel('Protein Length',  size=25)\n",
    "plt.ylabel('Density',  size=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THSA, RHSA and LHP Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.set_style(style='white')\n",
    "fig , ax = plt.subplots(figsize = (17,8))\n",
    "sns.set(font_scale = 1.55)\n",
    "\n",
    "cm = plt.cm.get_cmap('coolwarm')\n",
    "lp_all = lp_all.sort_values(by=['rhsa'], ascending=True)\n",
    "\n",
    "x = lp_all['size']\n",
    "y = lp_all['thsa']\n",
    "colors = lp_all['rhsa'] \n",
    "\n",
    "im = plt.scatter(x, y, s=60, c=colors, alpha=0.5, cmap=cm)\n",
    "fig.colorbar(im, ax=ax, label='RHSA')\n",
    "ax.set_xlabel('LHP($Å^2$)', fontsize=20)\n",
    "ax.set_ylabel('THSA($Å^2$)', fontsize=20)\n",
    "ax.set_title('Structure-based Data', fontsize=30)\n",
    "plt.show()\n",
    "\n",
    "#fig.savefig(my_path + 'THSA_RHSA_LHPSA_Scatter_structure-based.png', dpi = 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The same plot for the human proteome data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig , ax = plt.subplots(figsize = (17,8))\n",
    "sns.set(font_scale = 1.55)\n",
    "\n",
    "cm = plt.cm.get_cmap('coolwarm')\n",
    "hg = hg.sort_values(by=['RHSA'], ascending=True)\n",
    "\n",
    "x = hg['LHPSA']\n",
    "y = hg['THSA']\n",
    "colors =hg['RHSA'] \n",
    "\n",
    "im = plt.scatter(x, y, s=60, c=colors, alpha=0.5, cmap=cm)\n",
    "fig.colorbar(im, ax=ax, label='RHSA')\n",
    "ax.set_xlabel('LHP($Å^2$)', fontsize=20)\n",
    "ax.set_ylabel('THSA($Å^2$)', fontsize=20)\n",
    "ax.set_title('Human Proteome Predictions', fontsize=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing GSEA on Disease pathways and overlapping proteins with KEGG ND gene sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEGG_PD = my_path + '/KEGG_PARKINSONS_DISEASE.tsv'\n",
    "KEGG_PD = pd.read_csv(KEGG_PD, sep='\\t', engine='python')\n",
    "KEGG_PD = KEGG_PD.rename(columns = {'SYMBOL': 'Gene_ID'}, inplace = False)\n",
    "KEGG_PD = pd.merge(hg, KEGG_PD, on='Gene_ID')\n",
    "\n",
    "KEGG_HD = my_path + '/KEGG_HUNTINGTONS_DISEASE.tsv'\n",
    "KEGG_HD = pd.read_csv(KEGG_HD, sep='\\t', engine='python')\n",
    "KEGG_HD = KEGG_HD.rename(columns = {'SYMBOL': 'Gene_ID'}, inplace = False)\n",
    "KEGG_HD = pd.merge(hg, KEGG_HD, on='Gene_ID')\n",
    "\n",
    "KEGG_AD = my_path + '/KEGG_ALZHEIMERS_DISEASE.tsv'\n",
    "KEGG_AD = pd.read_csv(KEGG_AD, sep='\\t', engine='python')\n",
    "KEGG_AD = KEGG_AD.rename(columns = {'SYMBOL': 'Gene_ID'}, inplace = False)\n",
    "KEGG_AD = pd.merge(hg, KEGG_AD, on='Gene_ID')\n",
    "\n",
    "print('overlapping proteins with KEGG Parkinsons', KEGG_PD['length'].median(), 'amino acid residues')\n",
    "print('overlapping proteins with KEGG Huntingtons', KEGG_HD['length'].median(), 'amino acid residues')\n",
    "print('overlapping proteins with KEGG Alzheimers', KEGG_AD['length'].median(), 'amino acid residues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mRNA Expression Consensus data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus = consensus.rename(columns = {'Gene name': 'Gene_ID'}, inplace = False)\n",
    "consensus = pd.merge(hg, consensus, on='Gene_ID')\n",
    "consensus_wtmp = consensus[~consensus['Uniprot_ID'].isin(TM_uniprot)] # without transmembrane proteins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Hydrophobicity = Tissue-specific average surface hydrophobicity (TASH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tissue_hydrophobicity(df):\n",
    "    df['NX_THSA'] = df['NX']*df['THSA']\n",
    "    df['NX_RHSA'] = df['NX']*df['RHSA']\n",
    "    df['NX_LHPSA'] = df['NX']*df['LHPSA']\n",
    "\n",
    "    df['sum_NX']= df.groupby(\"Tissue\")[\"NX\"].transform('sum')\n",
    "    df['sum_NX_THSA']= df.groupby(\"Tissue\")[\"NX_THSA\"].transform('sum')\n",
    "    df['sum_NX_RHSA']= df.groupby(\"Tissue\")[\"NX_RHSA\"].transform('sum')\n",
    "    df['sum_NX_LHPSA']= df.groupby(\"Tissue\")[\"NX_LHPSA\"].transform('sum')\n",
    "\n",
    "    df['h_THSA'] = df['sum_NX_THSA']/df['sum_NX']\n",
    "    df['h_RHSA'] = df['sum_NX_RHSA']/df['sum_NX']\n",
    "    df['h_LHPSA'] = df['sum_NX_LHPSA']/df['sum_NX']\n",
    "    df = df[['Tissue', 'h_THSA', 'h_RHSA', 'h_LHPSA']]\n",
    "    df = df.drop_duplicates(subset=['Tissue'])\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_h_wtmp = tissue_hydrophobicity(consensus_wtmp)\n",
    "overall_h_wtmp = overall_h_wtmp.sort_values('h_THSA', ascending=False)\n",
    "overall_h = tissue_hydrophobicity(consensus)\n",
    "overall_h = overall_h.sort_values('h_THSA', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the data sets\n",
    "overall_h_wtmp.columns = ['Tissue', 'h_THSA_wtmp', 'h_RHSA_wtmp', 'h_LHPSA_wtmp']\n",
    "TASH = pd.merge(overall_h, overall_h_wtmp, on='Tissue')\n",
    "TASH.columns = ['Tissue', 'THSA', 'RHSA', 'LHP', 'THSA#', 'RHSA#', 'LHP#']\n",
    "#TASH.to_csv(my_path + '/TASH.csv', sep= ',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import dataframe_image as dfi\n",
    "\n",
    "s = TASH.style\\\n",
    "    .background_gradient(cmap='coolwarm', subset=['THSA'])\\\n",
    "    .background_gradient(cmap='coolwarm', subset=['RHSA'])\\\n",
    "    .background_gradient(cmap='coolwarm', subset=['LHP'])\\\n",
    "    .background_gradient(cmap='coolwarm', subset=['THSA#'])\\\n",
    "    .background_gradient(cmap='coolwarm', subset=['RHSA#'])\\\n",
    "    .background_gradient(cmap='coolwarm', subset=['LHP#'])\n",
    "#dfi.export(s, my_path + 'TASH_table.png')\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relationship between mRNA expression data and THSA, RHSA, LHP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus = my_path + '/rna_consensus.tsv'\n",
    "consensus = pd.read_csv(consensus, sep='\\t', engine='python') #mRNA expression consensus data from HPA\n",
    "\n",
    "consensus = consensus.rename(columns = {'Gene name': 'Gene_ID'}, inplace = False)\n",
    "consensus = pd.merge(hg, consensus, on='Gene_ID')\n",
    "#consensus_wtmp = consensus[~consensus['Uniprot_ID'].isin(TM_uniprot)] # without transmembrane proteins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis normalised expression (NX) value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate median NX value per gene across all the tissues that a gene appears in\n",
    "consensus['Median_NX'] = consensus.groupby(['Gene_ID'])['NX'].transform('median') \n",
    "\n",
    "#keep only one entry per gene by dropping duplicates \n",
    "#and keeping also the highest NX value per gene across the tissues\n",
    "NX_median = consensus.sort_values('NX').drop_duplicates(subset=['Gene_ID'], keep='last') #df for analysing median NX value\n",
    "NX_highest = consensus.sort_values('NX').drop_duplicates(subset=['Gene_ID'], keep='last') #df for analysing the highest NX value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Highest NX value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NX_highest['NX'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_highest_NX(df):\n",
    "    if df['NX'] <= 11.7:\n",
    "        return 'A'\n",
    "    elif df['NX'] > 11.7 and df['NX'] <= 21.4:\n",
    "        return 'B'\n",
    "    elif df['NX'] > 21.4 and df['NX'] <= 28.6:\n",
    "        return 'C'\n",
    "    elif df['NX'] > 28.6 and df['NX'] <= 35:\n",
    "        return 'D'\n",
    "    elif df['NX'] > 35 and df['NX'] <= 42.3:\n",
    "        return 'E'\n",
    "    elif df['NX'] > 42.3 and df['NX'] <= 51.2:\n",
    "        return 'F'    \n",
    "    elif df['NX'] > 51.2 and df['NX'] <= 63.7:\n",
    "        return 'G'    \n",
    "    elif df['NX'] > 63.7 and df['NX'] <= 84.2:\n",
    "        return 'H'    \n",
    "    elif df['NX'] > 84.2 and df['NX'] <= 130.5:\n",
    "        return 'I'    \n",
    "    elif df['NX'] > 130.5:\n",
    "        return 'J'    \n",
    "    \n",
    "NX_highest['Expression'] = NX_highest.apply(classifier_highest_NX, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To check the groups\n",
    "#Expression = NX_highest.groupby('Expression').count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.violinplot(x=\"Expression\", y=\"THSA\", data=NX_highest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ax = sns.violinplot(x=\"Expression\", y=\"RHSA\", data=NX_highest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ax = sns.violinplot(x=\"Expression\", y=\"LHPSA\", data=NX_highest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Transmembrane proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NX_highest_wtmp = NX_highest[~NX_highest['Uniprot_ID'].isin(TM_uniprot)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.violinplot(x=\"Expression\", y=\"THSA\", data=NX_highest_wtmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ax = sns.violinplot(x=\"Expression\", y=\"RHSA\", data=NX_highest_wtmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ax = sns.violinplot(x=\"Expression\", y=\"LHPSA\", data=NX_highest_wtmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "consensus['Median_NX'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_median(df):\n",
    "    if df['Median_NX'] <= 1.4:\n",
    "        return 'Low'\n",
    "    elif df['Median_NX'] > 1.4 and df['Median_NX'] <= 10.3:\n",
    "        return 'Medium'\n",
    "    elif df['Median_NX'] > 10.3:\n",
    "        return 'High'\n",
    "    \n",
    "NX_median['Expression'] = NX_median.apply(classifier_median, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the groups\n",
    "#Expression = NX_median.groupby('Expression').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.violinplot(x=\"Expression\", y=\"THSA\", data=NX_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ax = sns.violinplot(x=\"Expression\", y=\"RHSA\", data=NX_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ax = sns.violinplot(x=\"Expression\", y=\"LHPSA\", data=NX_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing outliers, Check what kind of proteins are on top (high expression and high hydrophobicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NX_median_wtmp = NX_median[~NX_median['Uniprot_ID'].isin(TM_uniprot)] #removing transmembrane proteins\n",
    "outliers = NX_median_wtmp[NX_median_wtmp['Expression'] == 'High']\n",
    "outliers = outliers[outliers['RHSA'] > 0.4]\n",
    "outliers = outliers[outliers['LHPSA'] > 2000]\n",
    "outliers = outliers[outliers['THSA'] > 1500]\n",
    "outliers = outliers.sort_values('NX')\n",
    "\n",
    "all_uniprot = my_path + '/uniprot_9606.tab' # need to import once again to have all the info\n",
    "all_uniprot = pd.read_csv(all_uniprot, sep='\\t', engine='python') #all information from Uniprot only\n",
    "all_uniprot.columns = ['Uniprot_ID', 'x1', 'x2', 'x3', 'Gene_ID', 'Protein', 'x5', 'x6', 'length']\n",
    "all_uniprot = all_uniprot[['Uniprot_ID', 'Protein']]\n",
    "outliers = pd.merge(outliers, all_uniprot, on='Uniprot_ID')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
